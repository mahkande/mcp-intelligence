"""
Pylance MCP Server

Main entrypoint for the production-ready Pylance MCP server.
Exposes Pyright/Pylance language server capabilities via MCP protocol.
"""

import json
import logging
import os
import sys
import threading
import urllib.error
import urllib.request
from pathlib import Path
from typing import Any, Dict, List, Optional

from fastmcp import FastMCP
from fastapi import FastAPI
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware

from mcp_server.pylance_bridge import PylanceBridge
from mcp_server.resources import PylanceResources
from mcp_server.tools import PylanceTools
from mcp_server.logging_db import get_logger, ConversationLogger
from mcp_server.tracing import setup_tracing, get_tracer
from mcp_server.api_routes import api_router

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()],
)
logger = logging.getLogger(__name__)

# Determine workspace root
WORKSPACE_ROOT = os.environ.get("WORKSPACE_ROOT", os.getcwd())
workspace_path = Path(WORKSPACE_ROOT).resolve()

# Initialize FastAPI app
app = FastAPI(
    title="Pylance MCP Pro API",
    description="REST API for Python code intelligence with Pylance/Pyright integration, OpenTelemetry tracing, and advanced code analysis",
    version="1.0.0"
)

# Initialize FastMCP for MCP protocol support
mcp = FastMCP(name="Pylance MCP Pro")

# Add CORS middleware for website access
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",
        "https://pylancemcp.com",
        "https://www.pylancemcp.com"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Mount REST API routes
app.include_router(api_router)

# Startup event to initialize server
@app.on_event("startup")
async def startup_event():
    """Initialize server on startup."""
    initialize_server()
    logger.info("Server initialized and ready")

# Add prompts for discoverability in Copilot Chat
@mcp.prompt()
def pylance_help() -> str:
    """
    Get help on available Pylance MCP Pro tools for Python code intelligence.
    
    Returns helpful information about using the Pylance MCP Pro server tools.
    """
    return """# Pylance MCP Pro - Available Tools

This server provides Python language intelligence via Pylance/Pyright.

## Available Tools:

1. **get_completions** - Get code completions at a specific position
2. **get_hover** - Get type hints and documentation for a symbol
3. **get_definition** - Find where a symbol is defined
4. **get_references** - Find all references to a symbol
5. **rename_symbol** - Rename a symbol across the workspace
6. **get_diagnostics** - Get errors, warnings, and type issues
7. **format_document** - Format Python code
8. **apply_workspace_edit** - Apply code changes
9. **get_signature_help** - Get function signature information
10. **get_document_symbols** - Get outline/symbols in a file
11. **get_workspace_symbols** - Search for symbols in workspace
12. **health_check** - Check server health

## Resources:

- **file://{path}** - Read any file in the workspace
- **workspace://files** - List all Python files
- **workspace://structure** - Get workspace directory structure

## Usage:

Ask natural questions about Python code and the tools will be used automatically!
Examples:
- "What's the type of this variable?"
- "Show me where this function is used"
- "Are there any errors in this file?"
"""

# Initialize Pylance bridge and helpers
bridge: PylanceBridge = None
tools: PylanceTools = None
resources: PylanceResources = None
conv_logger: ConversationLogger = None
conversation_id: int = None

_init_lock = threading.Lock()
_init_done = threading.Event()
_init_started = False
_init_error: Optional[str] = None

EXPORTED_MCP_TOOL_NAMES = [
    "get_completions",
    "get_hover",
    "get_definition",
    "get_references",
    "rename_symbol",
    "get_diagnostics",
    "format_document",
    "apply_workspace_edit",
    "type_check",
    "get_python_environment",
    "set_python_environment",
    "health_check",
    "pylanceWorkspaceRoots",
    "pylanceWorkspaceUserFiles",
    "pylanceSettings",
    "pylancePythonEnvironments",
    "pylanceUpdatePythonEnvironment",
    "pylanceInstalledTopLevelModules",
    "pylanceImports",
    "pylanceFileSyntaxErrors",
    "pylanceSyntaxErrors",
    "pylanceRunCodeSnippet",
    "pylanceInvokeRefactoring",
    "pylanceDocuments",
    "export_training_data",
    "get_logging_statistics",
    "log_user_prompt",
    "log_assistant_response",
    "lint_code",
    "fix_lint_issues",
    "security_scan",
    "analyze_complexity",
]

# Health check endpoints
@app.get("/health")
async def http_health_check():
    """Railway health check endpoint."""
    return JSONResponse({
        "status": "healthy",
        "service": "pylance-mcp-server",
        "workspace": str(workspace_path),
        "bridge_active": bridge is not None and bridge.is_running()
    })

@app.get("/")
async def root():
    """Root endpoint."""
    return JSONResponse({
        "service": "pylance-mcp-server",
        "version": "1.0.0",
        "status": "running"
    })


def initialize_server():
    """Initialize the Pylance bridge and tool/resource handlers."""
    global bridge, tools, resources, conv_logger, conversation_id, _init_started, _init_error
    
    try:
        with _init_lock:
            if _init_done.is_set() and tools and resources and bridge and bridge.initialized:
                return
            if _init_started and not _init_done.is_set():
                return
            _init_started = True

        logger.info(f"Initializing Pylance MCP Pro for workspace: {workspace_path}")
        
        # Initialize tracing
        setup_tracing(service_name="pylance-mcp-pro")
        logger.info("Tracing initialized")
        
        # Initialize conversation logger (training data collection)
        enable_training = os.environ.get("ENABLE_TRAINING", "true").lower() in ("true", "1", "yes")
        if enable_training:
            conv_logger = get_logger()
            logger.info("Training data logging ENABLED")
            
            # Start conversation session
            import uuid
            session_id = str(uuid.uuid4())
            conversation_id = conv_logger.start_conversation(
                session_id=session_id,
                workspace_root=str(workspace_path),
                python_version=f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
                metadata={"server_version": "1.0.0", "training_enabled": True}
            )
            logger.info(f"Started conversation logging: session_id={session_id}, conversation_id={conversation_id}")
        else:
            conv_logger = None
            conversation_id = None
            logger.info("Training data logging DISABLED")
        
        # Initialize bridge
        bridge = PylanceBridge(str(workspace_path))
        bridge.start()
        
        # Initialize tools and resources
        tools = PylanceTools(bridge)
        resources = PylanceResources(str(workspace_path))
        
        logger.info("Pylance MCP server initialized successfully")
        _init_error = None
        _init_done.set()
    except Exception as e:
        logger.error(f"Failed to initialize server: {e}")
        _init_error = str(e)
        _init_done.set()
        raise


def start_initialization_background() -> None:
    global _init_started
    with _init_lock:
        if _init_done.is_set() or _init_started:
            return
        _init_started = True

    def _runner():
        try:
            initialize_server()
        except Exception:
            return

    threading.Thread(target=_runner, daemon=True).start()


def ensure_initialized(wait_seconds: float = 60.0) -> None:
    if _init_done.is_set():
        if _init_error:
            raise RuntimeError(f"Server initialization failed: {_init_error}")
        return

    start_initialization_background()
    if not _init_done.wait(timeout=wait_seconds):
        raise RuntimeError("Server is still initializing. Try again in a moment.")
    if _init_error:
        raise RuntimeError(f"Server initialization failed: {_init_error}")


# ==================== MCP TOOLS ====================

def log_tool_call(tool_name: str):
    """Decorator to log tool calls for training data."""
    def decorator(func):
        def wrapper(*args, **kwargs):
            import time
            start_time = time.time()
            
            # Capture arguments
            arguments = {
                'args': args,
                'kwargs': kwargs
            }
            
            try:
                # Execute tool
                result = func(*args, **kwargs)
                
                # Calculate execution time
                execution_time_ms = (time.time() - start_time) * 1000
                
                # Log successful tool call
                if conv_logger and conversation_id:
                    conv_logger.log_tool_call(
                        conversation_id=conversation_id,
                        tool_name=tool_name,
                        arguments=arguments,
                        result=result,
                        success=True,
                        execution_time_ms=execution_time_ms
                    )
                
                return result
                
            except Exception as e:
                # Calculate execution time
                execution_time_ms = (time.time() - start_time) * 1000
                
                # Log failed tool call
                if conv_logger and conversation_id:
                    conv_logger.log_tool_call(
                        conversation_id=conversation_id,
                        tool_name=tool_name,
                        arguments=arguments,
                        result=None,
                        success=False,
                        error_message=str(e),
                        execution_time_ms=execution_time_ms
                    )
                
                raise
        
        return wrapper
    return decorator


@mcp.tool()
def get_completions(file_path: str, line: int, character: int, content: str) -> List[Dict[str, Any]]:
    """
    Return Pylance completions at exact position.
    
    Args:
        file_path: Relative or absolute path to the Python file
        line: Line number (0-indexed)
        character: Character position (0-indexed)
        content: Full content of the file
    
    Returns:
        List of LSP completion items with labels, kinds, and details
    """
    ensure_initialized()
    
    tracer = get_tracer()
    with tracer.start_as_current_span("get_completions") as span:
        span.set_attribute("file_path", file_path)
        span.set_attribute("line", line)
        span.set_attribute("character", character)
        
        @log_tool_call("get_completions")
        def _execute():
            return tools.get_completions(file_path, line, character, content)
        
        return _execute()


@mcp.tool()
def get_hover(file_path: str, line: int, character: int, content: str) -> str:
    """
    Return hover information (type signature + docstring).
    
    Args:
        file_path: Relative or absolute path to the Python file
        line: Line number (0-indexed)
        character: Character position (0-indexed)
        content: Full content of the file
    
    Returns:
        Hover information as markdown string
    """
    ensure_initialized()
    
    tracer = get_tracer()
    with tracer.start_as_current_span("get_hover") as span:
        span.set_attribute("file_path", file_path)
        span.set_attribute("line", line)
        span.set_attribute("character", character)
        
        @log_tool_call("get_hover")
        def _execute():
            return tools.get_hover(file_path, line, character, content)
        
        return _execute()


@mcp.tool()
def get_definition(file_path: str, line: int, character: int, content: str) -> List[Dict[str, Any]]:
    """
    Go-to definition - returns location(s).
    
    Args:
        file_path: Relative or absolute path to the Python file
        line: Line number (0-indexed)
        character: Character position (0-indexed)
        content: Full content of the file
    
    Returns:
        List of location dictionaries with uri and range
    """
    ensure_initialized()
    
    @log_tool_call("get_definition")
    def _execute():
        return tools.get_definition(file_path, line, character, content)
    
    return _execute()


@mcp.tool()
def get_references(
    file_path: str, line: int, character: int, content: str, include_declaration: bool = True
) -> List[Dict[str, Any]]:
    """
    Find all references across the entire workspace.
    
    Args:
        file_path: Relative or absolute path to the Python file
        line: Line number (0-indexed)
        character: Character position (0-indexed)
        content: Full content of the file
        include_declaration: Whether to include the declaration
    
    Returns:
        List of location dictionaries with uri and range
    """
    ensure_initialized()
    
    @log_tool_call("get_references")
    def _execute():
        return tools.get_references(file_path, line, character, content, include_declaration)
    
    return _execute()


@mcp.tool()
def rename_symbol(
    file_path: str, line: int, character: int, new_name: str, content: str
) -> Dict[str, Any]:
    """
    Returns workspace edit JSON for renaming a symbol.
    
    Args:
        file_path: Relative or absolute path to the Python file
        line: Line number (0-indexed)
        character: Character position (0-indexed)
        new_name: New name for the symbol
        content: Full content of the file
    
    Returns:
        LSP WorkspaceEdit dictionary with changes to apply
    """
    ensure_initialized()
    
    @log_tool_call("rename_symbol")
    def _execute():
        return tools.rename_symbol(file_path, line, character, new_name, content)
    
    return _execute()


@mcp.tool()
def get_diagnostics(file_path: str, content: str) -> List[Dict[str, Any]]:
    """
    Return Pyright diagnostics (errors, warnings, suggestions).
    
    Args:
        file_path: Relative or absolute path to the Python file
        content: Full content of the file
    
    Returns:
        List of diagnostic dictionaries with severity, message, and range
    """
    ensure_initialized()
    
    @log_tool_call("get_diagnostics")
    def _execute():
        return tools.get_diagnostics(file_path, content)
    
    return _execute()


@mcp.tool()
def format_document(file_path: str, content: str) -> str:
    """
    Return fully formatted code.
    
    Args:
        file_path: Relative or absolute path to the Python file
        content: Full content of the file
    
    Returns:
        Formatted code as string
    """
    ensure_initialized()
    
    @log_tool_call("format_document")
    def _execute():
        return tools.format_document(file_path, content)
    
    return _execute()


@mcp.tool()
def apply_workspace_edit(edit: Dict[str, Any]) -> Dict[str, Any]:
    """
    Take LSP WorkspaceEdit JSON and return file write instructions.
    
    Args:
        edit: LSP WorkspaceEdit dictionary
    
    Returns:
        Dictionary with success status and file paths mapped to new content
    """
    ensure_initialized()
    
    @log_tool_call("apply_workspace_edit")
    def _execute():
        result = tools.apply_workspace_edit(edit)
        
        # Log file modifications
        if conv_logger and conversation_id and result.get('success'):
            # Get the last tool call ID
            tool_calls = conv_logger.get_tool_calls(conversation_id)
            if tool_calls:
                last_tool_call_id = tool_calls[-1]['id']
                
                # Log each file modification
                for file_path, new_content in result.get('files', {}).items():
                    # Estimate lines added/removed (simplified)
                    lines_added = len(new_content.splitlines()) if new_content else 0
                    conv_logger.log_file_modification(
                        tool_call_id=last_tool_call_id,
                        file_path=file_path,
                        operation='edit',
                        lines_added=lines_added
                    )
        
        return result
    
    return _execute()


# ==================== MCP RESOURCES ====================

@mcp.resource("file://{path}")
def read_file(path: str) -> str:
    """
    Read file content.
    
    Args:
        path: Relative or absolute path to the file
    
    Returns:
        File content as string
    """
    ensure_initialized()
    return resources.read_file(path)


@mcp.resource("workspace://files")
def list_workspace_files() -> List[str]:
    """
    Return every .py file in the current project recursively.
    
    Returns:
        List of relative file paths to Python files
    """
    ensure_initialized()
    return resources.list_workspace_files()


@mcp.resource("workspace://structure")
def get_workspace_structure() -> Dict[str, Any]:
    """
    Get the complete workspace directory structure.
    
    Returns:
        Dictionary representing the directory tree
    """
    ensure_initialized()
    return resources.get_workspace_structure()


# ==================== TYPE CHECKING ====================

@mcp.tool()
def type_check(file_path: Optional[str] = None, content: Optional[str] = None) -> Dict[str, Any]:
    """
    Run Pyright type checking on a file or entire workspace.
    
    Args:
        file_path: Optional path to specific file. If None, checks entire workspace.
        content: Optional file content. If provided with file_path, checks this content.
                If None, reads from disk.
    
    Returns:
        Dictionary with type checking results including summary and diagnostics
    """
    ensure_initialized()
    
    @log_tool_call("type_check")
    def _execute():
        return tools.type_check(file_path, content)
    
    return _execute()


# ==================== HEALTH CHECK ====================

@mcp.tool()
def health_check() -> Dict[str, str]:
    """
    Health check endpoint.
    
    Returns:
        Status dictionary
    """
    python_path = bridge.python_path if bridge else None
    return {
        "status": "ok",
        "mcp": "pylance-mcp",
        "version": "1.0.0",
        "workspace": str(workspace_path),
        "bridge_initialized": bridge is not None and bridge.initialized,
        "python_environment": python_path or "system",
    }


@mcp.tool()
def get_python_environment() -> Dict[str, Any]:
    """
    Get information about the detected Python environment.
    
    Returns:
        Dictionary with Python environment details
    """
    ensure_initialized()
    
    return {
        "python_path": bridge.python_path,
        "workspace_root": str(workspace_path),
        "venv_detected": bridge.python_path is not None and any(
            venv_name in bridge.python_path 
            for venv_name in ['.venv', 'venv', 'env', '.env']
        ),
        "pyrightconfig_exists": (workspace_path / 'pyrightconfig.json').exists()
    }


@mcp.tool()
def set_python_environment(python_path: str) -> Dict[str, Any]:
    """
    Manually set the Python environment path.
    
    Useful when automatic detection fails or customer wants to use a specific Python interpreter.
    This will restart the language server with the new Python path.
    
    Args:
        python_path: Absolute path to Python executable
    
    Returns:
        Status of the operation
    """
    ensure_initialized()
    
    from pathlib import Path
    python_exe = Path(python_path)
    
    if not python_exe.exists():
        return {
            "success": False,
            "error": f"Python executable not found: {python_path}"
        }
    
    # Update bridge's Python path
    bridge.python_path = str(python_exe.resolve())
    
    # Restart the language server with new Python path
    try:
        bridge.stop()
        bridge.start()
        
        return {
            "success": True,
            "python_path": bridge.python_path,
            "message": "Language server restarted with new Python environment"
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@mcp.tool()
def pylanceWorkspaceRoots() -> List[str]:
    return [str(workspace_path)]


@mcp.tool()
def pylanceWorkspaceUserFiles(max_files: int = 5000) -> List[str]:
    ensure_initialized()
    files = resources.list_workspace_files()
    return files[:max_files]


@mcp.tool()
def pylanceSettings() -> Dict[str, Any]:
    pyrightconfig_path = workspace_path / "pyrightconfig.json"
    vscode_settings_path = workspace_path / ".vscode" / "settings.json"

    pyrightconfig = None
    vscode_settings = None

    try:
        if pyrightconfig_path.exists():
            import json
            pyrightconfig = json.loads(pyrightconfig_path.read_text(encoding="utf-8"))
    except Exception:
        pyrightconfig = None

    try:
        if vscode_settings_path.exists():
            import json
            vscode_settings = json.loads(vscode_settings_path.read_text(encoding="utf-8"))
    except Exception:
        vscode_settings = None

    return {
        "workspace_root": str(workspace_path),
        "python_path": bridge.python_path if bridge else None,
        "pyrightconfig": pyrightconfig,
        "vscode_settings": vscode_settings,
    }


@mcp.tool()
def pylancePythonEnvironments() -> Dict[str, Any]:
    candidates: List[str] = []

    common_relative_paths = [
        Path(".venv") / "Scripts" / "python.exe",
        Path("venv") / "Scripts" / "python.exe",
        Path("env") / "Scripts" / "python.exe",
        Path(".venv") / "bin" / "python",
        Path("venv") / "bin" / "python",
        Path("env") / "bin" / "python",
    ]

    for rel in common_relative_paths:
        candidate = (workspace_path / rel).resolve()
        if candidate.exists():
            candidates.append(str(candidate))

    seen = set()
    deduped_candidates: List[str] = []
    for c in candidates:
        if c in seen:
            continue
        seen.add(c)
        deduped_candidates.append(c)

    return {
        "workspace_root": str(workspace_path),
        "detected_python_path": bridge.python_path if bridge else None,
        "candidates": deduped_candidates,
    }


@mcp.tool()
def pylanceUpdatePythonEnvironment(python_path: str) -> Dict[str, Any]:
    return set_python_environment(python_path)


@mcp.tool()
def pylanceInstalledTopLevelModules(limit: int = 2000) -> List[str]:
    import pkgutil

    modules = sorted({m.name for m in pkgutil.iter_modules()})
    return modules[:limit]


@mcp.tool()
def pylanceImports(max_files: int = 200) -> Dict[str, Any]:
    ensure_initialized()

    import ast

    files = resources.list_workspace_files()[:max_files]
    by_file: Dict[str, List[str]] = {}
    module_counts: Dict[str, int] = {}

    for rel_path in files:
        abs_path = (workspace_path / rel_path).resolve()
        try:
            content = abs_path.read_text(encoding="utf-8")
        except Exception:
            continue

        try:
            tree = ast.parse(content, filename=str(rel_path))
        except SyntaxError:
            continue

        modules_in_file: List[str] = []
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    name = (alias.name or "").split(".")[0].strip()
                    if name:
                        modules_in_file.append(name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    name = node.module.split(".")[0].strip()
                    if name:
                        modules_in_file.append(name)

        if not modules_in_file:
            continue

        unique = sorted(set(modules_in_file))
        by_file[str(rel_path)] = unique
        for mod in unique:
            module_counts[mod] = module_counts.get(mod, 0) + 1

    sorted_modules = sorted(module_counts.items(), key=lambda kv: (-kv[1], kv[0]))
    return {
        "files_scanned": len(files),
        "unique_modules": [m for m, _ in sorted_modules],
        "module_counts": dict(sorted_modules),
        "by_file": by_file,
    }


@mcp.tool()
def pylanceFileSyntaxErrors(file_path: str, content: Optional[str] = None) -> List[Dict[str, Any]]:
    import ast

    if content is None:
        ensure_initialized()
        try:
            content = resources.read_file(file_path)
        except Exception as e:
            return [{"message": str(e), "line": 0, "offset": 0}]

    try:
        ast.parse(content, filename=file_path)
        return []
    except SyntaxError as e:
        return [{
            "message": e.msg,
            "line": e.lineno or 0,
            "offset": e.offset or 0,
            "end_line": getattr(e, "end_lineno", None),
            "end_offset": getattr(e, "end_offset", None),
            "text": e.text.strip() if e.text else None,
        }]


@mcp.tool()
def pylanceSyntaxErrors(code: str, file_path: str = "<snippet>") -> List[Dict[str, Any]]:
    return pylanceFileSyntaxErrors(file_path=file_path, content=code)


@mcp.tool()
def pylanceRunCodeSnippet(
    code: str,
    timeout_seconds: int = 10,
) -> Dict[str, Any]:
    import subprocess
    import tempfile

    python_exe = bridge.python_path if bridge and bridge.python_path else sys.executable

    try:
        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False, encoding="utf-8") as f:
            f.write(code)
            temp_path = f.name

        completed = subprocess.run(
            [python_exe, temp_path],
            capture_output=True,
            text=True,
            cwd=str(workspace_path),
            timeout=timeout_seconds,
        )

        return {
            "success": completed.returncode == 0,
            "exit_code": completed.returncode,
            "stdout": completed.stdout,
            "stderr": completed.stderr,
        }
    except subprocess.TimeoutExpired as e:
        return {
            "success": False,
            "exit_code": None,
            "stdout": e.stdout or "",
            "stderr": e.stderr or f"Timed out after {timeout_seconds}s",
        }
    except Exception as e:
        return {
            "success": False,
            "exit_code": None,
            "stdout": "",
            "stderr": str(e),
        }


@mcp.tool()
def pylanceInvokeRefactoring(operation: str, params: Dict[str, Any]) -> Dict[str, Any]:
    op = (operation or "").strip()

    if op == "rename_symbol":
        required = ["file_path", "line", "character", "new_name", "content"]
        missing = [k for k in required if k not in params]
        if missing:
            return {"success": False, "error": f"Missing params: {', '.join(missing)}"}
        edit = rename_symbol(
            file_path=params["file_path"],
            line=int(params["line"]),
            character=int(params["character"]),
            new_name=str(params["new_name"]),
            content=str(params["content"]),
        )
        return {"success": True, "operation": op, "edit": edit}

    if op == "format_document":
        required = ["file_path", "content"]
        missing = [k for k in required if k not in params]
        if missing:
            return {"success": False, "error": f"Missing params: {', '.join(missing)}"}
        formatted = format_document(
            file_path=str(params["file_path"]),
            content=str(params["content"]),
        )
        return {"success": True, "operation": op, "content": formatted}

    if op == "apply_workspace_edit":
        if "edit" not in params:
            return {"success": False, "error": "Missing params: edit"}
        result = apply_workspace_edit(edit=params["edit"])
        return {"success": True, "operation": op, "result": result}

    return {
        "success": False,
        "error": f"Unsupported operation: {op}",
        "supported_operations": ["rename_symbol", "format_document", "apply_workspace_edit"],
    }


@mcp.tool()
def pylanceDocuments(query: Optional[str] = None) -> str:
    text = pylance_help()
    if not query:
        return text
    q = query.lower()
    matches = [line for line in text.splitlines() if q in line.lower()]
    return "\n".join(matches) if matches else text


# ==================== CONVERSATION LOGGING ====================

@mcp.tool()
def export_training_data(output_path: str, format: str = "jsonl") -> Dict[str, Any]:
    """
    Export all logged conversation data for LLM training.
    
    Args:
        output_path: Path where training data will be saved
        format: Export format - "jsonl" (one JSON per line) or "json" (single array)
    
    Returns:
        Status of export operation with file path and record count
    """
    if not conv_logger:
        return {
            "success": False,
            "error": "Conversation logger not initialized"
        }
    
    try:
        conv_logger.export_training_data(output_path, format)
        
        # Get statistics
        stats = conv_logger.get_statistics()
        
        return {
            "success": True,
            "output_path": output_path,
            "format": format,
            "total_conversations": stats['total_conversations'],
            "total_messages": stats['total_messages'],
            "total_tool_calls": stats['total_tool_calls']
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@mcp.tool()
def get_logging_statistics() -> Dict[str, Any]:
    """
    Get statistics about logged conversation data.
    
    Returns:
        Dictionary with statistics including total conversations, messages, tool calls, etc.
    """
    if not conv_logger:
        return {
            "error": "Conversation logger not initialized"
        }
    
    return conv_logger.get_statistics()


@mcp.tool()
def log_user_prompt(prompt: str, metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    Manually log a user prompt (useful for capturing AI chat input).
    
    Args:
        prompt: The user's prompt text
        metadata: Optional metadata about the prompt
    
    Returns:
        Status with message_id
    """
    if not conv_logger or not conversation_id:
        return {
            "success": False,
            "error": "Conversation logger not initialized"
        }
    
    try:
        from datetime import datetime

        message_id = conv_logger.log_user_message(
            conversation_id=conversation_id,
            content=prompt,
            metadata=metadata
        )
        
        return {
            "success": True,
            "message_id": message_id,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@mcp.tool()
def log_assistant_response(response: str, model_name: Optional[str] = None,
                          token_count: Optional[int] = None,
                          metadata: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """
    Manually log an AI assistant response (useful for capturing LLM output).
    
    Args:
        response: The assistant's response text
        model_name: Name of the LLM model (e.g., "claude-3-opus", "gpt-4")
        token_count: Number of tokens in the response
        metadata: Optional metadata about the response
    
    Returns:
        Status with message_id
    """
    if not conv_logger or not conversation_id:
        return {
            "success": False,
            "error": "Conversation logger not initialized"
        }
    
    try:
        from datetime import datetime
        
        message_id = conv_logger.log_assistant_message(
            conversation_id=conversation_id,
            content=response,
            model_name=model_name,
            token_count=token_count,
            metadata=metadata
        )
        
        return {
            "success": True,
            "message_id": message_id,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@mcp.tool()
def lint_code(file_path: str, content: Optional[str] = None) -> Dict[str, Any]:
    """
    Run Ruff linter on Python code for style, complexity, and quality checks.
    Ultra-fast linting (10-100x faster than Flake8/Pylint).
    
    Args:
        file_path: Relative or absolute path to the Python file
        content: Optional file content (if not provided, reads from file_path)
    
    Returns:
        Dictionary with linting results including errors, warnings, and suggestions
    """
    import subprocess
    import json
    from pathlib import Path
    
    try:
        # Resolve file path
        abs_path = tools._resolve_path(file_path) if tools else Path(file_path).resolve()
        
        # If content provided, write to temp file for linting
        if content:
            import tempfile
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(content)
                temp_path = f.name
            
            lint_path = temp_path
        else:
            lint_path = str(abs_path)
        
        # Run Ruff with JSON output
        result = subprocess.run(
            ['ruff', 'check', lint_path, '--output-format=json'],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        # Clean up temp file if used
        if content:
            import os
            os.unlink(temp_path)
        
        # Parse JSON output
        if result.stdout:
            diagnostics = json.loads(result.stdout)
        else:
            diagnostics = []
        
        # Organize by severity
        errors = [d for d in diagnostics if d.get('code', '').startswith('E')]
        warnings = [d for d in diagnostics if d.get('code', '').startswith('W')]
        suggestions = [d for d in diagnostics if not d.get('code', '').startswith(('E', 'W'))]
        
        return {
            "success": True,
            "file_path": str(abs_path),
            "total_issues": len(diagnostics),
            "errors": len(errors),
            "warnings": len(warnings),
            "suggestions": len(suggestions),
            "diagnostics": diagnostics,
            "summary": f"Found {len(diagnostics)} issues: {len(errors)} errors, {len(warnings)} warnings, {len(suggestions)} suggestions"
        }
        
    except FileNotFoundError:
        return {
            "success": False,
            "error": "Ruff not installed. Install with: pip install ruff"
        }
    except subprocess.TimeoutExpired:
        return {
            "success": False,
            "error": "Linting timed out (>30s)"
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Linting failed: {str(e)}"
        }


@mcp.tool()
def fix_lint_issues(file_path: str, content: Optional[str] = None) -> Dict[str, Any]:
    """
    Auto-fix linting issues with Ruff (fixes safe issues automatically).
    
    Args:
        file_path: Relative or absolute path to the Python file
        content: Optional file content (if provided, returns fixed content instead of modifying file)
    
    Returns:
        Dictionary with fixed content or file modification status
    """
    import subprocess
    from pathlib import Path
    
    try:
        # Resolve file path
        abs_path = tools._resolve_path(file_path) if tools else Path(file_path).resolve()
        
        # If content provided, work with temp file
        if content:
            import tempfile
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(content)
                temp_path = f.name
            
            # Run Ruff fix
            subprocess.run(
                ['ruff', 'check', temp_path, '--fix'],
                capture_output=True,
                timeout=30
            )
            
            # Read fixed content
            with open(temp_path, 'r') as f:
                fixed_content = f.read()
            
            # Clean up
            import os
            os.unlink(temp_path)
            
            return {
                "success": True,
                "fixed_content": fixed_content,
                "message": "Auto-fixed linting issues (returned in fixed_content)"
            }
        else:
            # Fix file in place
            result = subprocess.run(
                ['ruff', 'check', str(abs_path), '--fix'],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            return {
                "success": True,
                "file_path": str(abs_path),
                "message": f"Auto-fixed linting issues in {abs_path.name}",
                "output": result.stdout
            }
        
    except FileNotFoundError:
        return {
            "success": False,
            "error": "Ruff not installed. Install with: pip install ruff"
        }
    except subprocess.TimeoutExpired:
        return {
            "success": False,
            "error": "Fix operation timed out (>30s)"
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Fix failed: {str(e)}"
        }


@mcp.tool()
def security_scan(file_path: str, content: Optional[str] = None) -> Dict[str, Any]:
    """
    Scan Python code for security vulnerabilities using Bandit.
    Detects issues like hardcoded passwords, SQL injection, insecure functions, etc.
    
    Args:
        file_path: Relative or absolute path to the Python file
        content: Optional file content (if not provided, reads from file_path)
    
    Returns:
        Dictionary with security findings organized by severity
    """
    import subprocess
    import json
    from pathlib import Path
    
    try:
        # Resolve file path
        abs_path = tools._resolve_path(file_path) if tools else Path(file_path).resolve()
        
        # If content provided, write to temp file
        if content:
            import tempfile
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(content)
                temp_path = f.name
            
            scan_path = temp_path
        else:
            scan_path = str(abs_path)
        
        # Run Bandit with JSON output
        result = subprocess.run(
            ['bandit', '-f', 'json', scan_path],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        # Clean up temp file if used
        if content:
            import os
            os.unlink(temp_path)
        
        # Parse JSON output
        if result.stdout:
            report = json.loads(result.stdout)
        else:
            report = {"results": []}
        
        # Organize by severity
        high_severity = [r for r in report.get('results', []) if r.get('issue_severity') == 'HIGH']
        medium_severity = [r for r in report.get('results', []) if r.get('issue_severity') == 'MEDIUM']
        low_severity = [r for r in report.get('results', []) if r.get('issue_severity') == 'LOW']
        
        # Format findings
        findings = []
        for issue in report.get('results', []):
            findings.append({
                "severity": issue.get('issue_severity'),
                "confidence": issue.get('issue_confidence'),
                "issue_text": issue.get('issue_text'),
                "test_id": issue.get('test_id'),
                "test_name": issue.get('test_name'),
                "line_number": issue.get('line_number'),
                "code": issue.get('code', '').strip(),
                "more_info": issue.get('more_info')
            })
        
        return {
            "success": True,
            "file_path": str(abs_path),
            "total_issues": len(findings),
            "high_severity": len(high_severity),
            "medium_severity": len(medium_severity),
            "low_severity": len(low_severity),
            "findings": findings,
            "summary": f"Found {len(findings)} security issues: {len(high_severity)} high, {len(medium_severity)} medium, {len(low_severity)} low"
        }
        
    except FileNotFoundError:
        return {
            "success": False,
            "error": "Bandit not installed. Install with: pip install bandit"
        }
    except subprocess.TimeoutExpired:
        return {
            "success": False,
            "error": "Security scan timed out (>30s)"
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Security scan failed: {str(e)}"
        }


@mcp.tool()
def analyze_complexity(file_path: str, content: Optional[str] = None) -> Dict[str, Any]:
    """
    Analyze code complexity using Radon (cyclomatic complexity, maintainability index).
    Identifies overly complex functions that should be refactored.
    
    Args:
        file_path: Relative or absolute path to the Python file
        content: Optional file content (if not provided, reads from file_path)
    
    Returns:
        Dictionary with complexity metrics and refactoring recommendations
    """
    from pathlib import Path
    
    try:
        # Resolve file path
        abs_path = tools._resolve_path(file_path) if tools else Path(file_path).resolve()
        
        # Read content
        if content:
            code = content
        else:
            with open(abs_path, 'r', encoding='utf-8') as f:
                code = f.read()
        
        # Import radon
        try:
            from radon.complexity import cc_visit
            from radon.metrics import mi_visit, h_visit
        except ImportError:
            return {
                "success": False,
                "error": "Radon not installed. Install with: pip install radon"
            }
        
        # Calculate cyclomatic complexity
        complexity_results = cc_visit(code)
        
        # Calculate maintainability index
        mi_score = mi_visit(code, multi=True)
        
        # Calculate Halstead metrics
        h_metrics = h_visit(code)
        
        # Organize results
        functions = []
        for result in complexity_results:
            complexity_rating = result.letter  # A (simple) to F (very complex)
            
            # Determine recommendation
            if result.complexity <= 5:
                recommendation = "Simple - no action needed"
            elif result.complexity <= 10:
                recommendation = "Moderate - acceptable complexity"
            elif result.complexity <= 20:
                recommendation = "Complex - consider refactoring"
            else:
                recommendation = "Very complex - refactoring recommended"
            
            functions.append({
                "name": result.name,
                "type": result.type,  # function, method, class
                "line_number": result.lineno,
                "complexity": result.complexity,
                "complexity_rating": complexity_rating,
                "recommendation": recommendation
            })
        
        # Sort by complexity (highest first)
        functions.sort(key=lambda x: x['complexity'], reverse=True)
        
        # Maintainability index interpretation
        if mi_score >= 20:
            maintainability = "Excellent - highly maintainable"
        elif mi_score >= 10:
            maintainability = "Good - moderately maintainable"
        elif mi_score >= 0:
            maintainability = "Fair - difficult to maintain"
        else:
            maintainability = "Poor - very difficult to maintain"
        
        # Count complex functions
        complex_count = sum(1 for f in functions if f['complexity'] > 10)
        very_complex_count = sum(1 for f in functions if f['complexity'] > 20)
        
        return {
            "success": True,
            "file_path": str(abs_path),
            "total_functions": len(functions),
            "complex_functions": complex_count,
            "very_complex_functions": very_complex_count,
            "maintainability_index": round(mi_score, 2),
            "maintainability_rating": maintainability,
            "average_complexity": round(sum(f['complexity'] for f in functions) / len(functions), 2) if functions else 0,
            "max_complexity": max((f['complexity'] for f in functions), default=0),
            "functions": functions,
            "halstead_metrics": {
                "total_operators": h_metrics.total.h1 if h_metrics.total else 0,
                "total_operands": h_metrics.total.h2 if h_metrics.total else 0,
                "vocabulary": h_metrics.total.vocabulary if h_metrics.total else 0,
                "difficulty": round(h_metrics.total.difficulty, 2) if h_metrics.total and h_metrics.total.difficulty else 0
            },
            "summary": f"{len(functions)} functions analyzed: {very_complex_count} very complex, {complex_count} complex. Maintainability: {maintainability}"
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"Complexity analysis failed: {str(e)}"
        }


def _is_proxy_mode() -> bool:
    mode = (os.environ.get("PYLANCE_MCP_MODE", "") or "").lower()
    if mode in ("proxy", "remote"):
        return True
    return bool(os.environ.get("PYLANCE_MCP_REMOTE_URL"))


def _proxy_workspace_root() -> Path:
    root = os.environ.get("WORKSPACE_PATH") or os.environ.get("WORKSPACE_ROOT") or os.getcwd()
    return Path(root).resolve()


def _proxy_resolve_workspace_path(workspace_root: Path, file_path: str) -> Optional[Path]:
    if not file_path:
        return None
    candidate = Path(file_path)
    if not candidate.is_absolute():
        candidate = workspace_root / candidate
    try:
        resolved = candidate.resolve()
    except Exception:
        return None
    if resolved == workspace_root or workspace_root in resolved.parents:
        return resolved
    return None


def _proxy_read_text_file(file_path: Path) -> Optional[str]:
    try:
        return file_path.read_text(encoding="utf-8", errors="replace")
    except Exception:
        return None


def _proxy_list_py_files(workspace_root: Path, max_files: int) -> List[str]:
    results: List[str] = []
    skip_dir_names = {
        ".git",
        "node_modules",
        "__pycache__",
        ".venv",
        "venv",
        "env",
        ".env",
        "dist",
        "build",
    }

    for dirpath, dirnames, filenames in os.walk(workspace_root):
        dirnames[:] = [d for d in dirnames if d not in skip_dir_names and not d.startswith(".")]
        for name in filenames:
            if len(results) >= max_files:
                break
            if name.endswith(".py"):
                full = Path(dirpath) / name
                try:
                    results.append(str(full.relative_to(workspace_root)))
                except Exception:
                    continue
        if len(results) >= max_files:
            break

    results.sort()
    return results


def _proxy_workspace_tree(workspace_root: Path, max_depth: int) -> Dict[str, Any]:
    skip_dir_names = {
        ".git",
        "node_modules",
        "__pycache__",
        ".venv",
        "venv",
        "env",
        ".env",
        "dist",
        "build",
    }

    def build(dir_path: Path, depth: int) -> Dict[str, Any]:
        node: Dict[str, Any] = {
            "name": dir_path.name,
            "type": "directory",
            "path": str(dir_path.relative_to(workspace_root)) if dir_path != workspace_root else ".",
            "children": [],
        }
        if depth <= 0:
            return node
        try:
            entries = list(dir_path.iterdir())
        except Exception:
            return node
        for entry in entries:
            if entry.name.startswith(".") and entry.name != ".gitignore":
                continue
            if entry.is_dir():
                if entry.name in skip_dir_names:
                    continue
                node["children"].append(build(entry, depth - 1))
            elif entry.is_file():
                try:
                    rel = entry.relative_to(workspace_root)
                except Exception:
                    continue
                node["children"].append({"name": entry.name, "type": "file", "path": str(rel)})
        return node

    return build(workspace_root, max_depth)


def _proxy_http_json(url: str, method: str, headers: Dict[str, str], body: Optional[Dict[str, Any]], timeout_s: float) -> Dict[str, Any]:
    data = json.dumps(body).encode("utf-8") if body is not None else None
    request_headers = dict(headers or {})
    if data is not None:
        request_headers.setdefault("Content-Type", "application/json")
        request_headers["Content-Length"] = str(len(data))

    req = urllib.request.Request(url=url, data=data, headers=request_headers, method=method)
    try:
        with urllib.request.urlopen(req, timeout=timeout_s) as resp:
            raw = resp.read()
            text = raw.decode("utf-8", errors="replace")
            try:
                parsed = json.loads(text) if text else None
            except Exception:
                parsed = None
            return {"status": getattr(resp, "status", 0) or 0, "json": parsed, "text": text}
    except urllib.error.HTTPError as e:
        raw = e.read()
        text = raw.decode("utf-8", errors="replace")
        try:
            parsed = json.loads(text) if text else None
        except Exception:
            parsed = None
        return {"status": int(getattr(e, "code", 0) or 0), "json": parsed, "text": text}


def _proxy_send_response(msg_id: Any, result: Any = None, error: Optional[Dict[str, Any]] = None) -> None:
    payload: Dict[str, Any] = {"jsonrpc": "2.0", "id": msg_id}
    if error is not None:
        payload["error"] = error
    else:
        payload["result"] = result
    sys.stdout.write(json.dumps(payload) + "\n")
    sys.stdout.flush()


def _proxy_normalize_tool_args(workspace_root: Path, name: str, args: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    a: Dict[str, Any] = dict(args or {})
    file_path = a.get("file_path")
    if file_path and "content" not in a and "code" not in a:
        resolved = _proxy_resolve_workspace_path(workspace_root, str(file_path))
        if resolved:
            content = _proxy_read_text_file(resolved)
            if content is not None:
                a["content"] = content
    if name == "pylanceFileSyntaxErrors" and file_path and a.get("content") is None:
        resolved = _proxy_resolve_workspace_path(workspace_root, str(file_path))
        if resolved:
            content = _proxy_read_text_file(resolved)
            if content is not None:
                a["content"] = content
    if name == "pylanceSyntaxErrors" and a.get("code") is None and a.get("content") is not None:
        a["code"] = a.get("content")
    return a


def _run_proxy_stdio() -> None:
    workspace_root = _proxy_workspace_root()
    remote_base = (os.environ.get("PYLANCE_MCP_REMOTE_URL") or "http://localhost:8080").rstrip("/")
    api_key = os.environ.get("PYLANCE_API_KEY") or os.environ.get("PYLANCE_MCP_API_KEY") or os.environ.get("PYRIGHT_API_KEY") or ""
    tools_list_url = f"{remote_base}/api/v1/mcp/tools/list"
    tools_call_url = f"{remote_base}/api/v1/mcp/tools/call"

    for line in sys.stdin:
        line = line.strip()
        if not line:
            continue
        try:
            msg = json.loads(line)
        except Exception:
            continue
        msg_id = msg.get("id")
        method = msg.get("method")
        params = msg.get("params") or {}

        try:
            if method == "initialize":
                _proxy_send_response(
                    msg_id,
                    {
                        "protocolVersion": "2024-11-05",
                        "serverInfo": {"name": "Pylance MCP Pro Proxy", "version": "1.0.0"},
                        "capabilities": {"tools": {}, "resources": {}},
                    },
                )
                continue

            if method == "tools/list":
                headers = {"x-api-key": api_key} if api_key else {}
                resp = _proxy_http_json(tools_list_url, "GET", headers, None, timeout_s=15.0)
                if 200 <= resp["status"] < 300 and isinstance(resp.get("json"), dict) and "tools" in resp["json"]:
                    _proxy_send_response(msg_id, {"tools": resp["json"]["tools"]})
                else:
                    _proxy_send_response(msg_id, error={"code": -32000, "message": f"tools/list failed ({resp['status']})", "data": resp.get("text")})
                continue

            if method == "tools/call":
                name = params.get("name")
                arguments_obj = _proxy_normalize_tool_args(workspace_root, str(name or ""), params.get("arguments") or {})
                headers = {"x-api-key": api_key} if api_key else {}
                resp = _proxy_http_json(tools_call_url, "POST", headers, {"name": name, "arguments": arguments_obj}, timeout_s=60.0)
                if 200 <= resp["status"] < 300 and isinstance(resp.get("json"), dict):
                    if "content" in resp["json"]:
                        _proxy_send_response(msg_id, resp["json"]["content"])
                    else:
                        _proxy_send_response(msg_id, resp["json"])
                else:
                    _proxy_send_response(msg_id, error={"code": -32000, "message": f"tools/call failed ({resp['status']})", "data": resp.get("text")})
                continue

            if method == "resources/list":
                _proxy_send_response(
                    msg_id,
                    {
                        "resources": [
                            {"uri": "file://{path}", "description": "Read any file in the workspace"},
                            {"uri": "workspace://files", "description": "List all Python files"},
                            {"uri": "workspace://structure", "description": "Get workspace directory structure"},
                        ]
                    },
                )
                continue

            if method == "resources/read":
                uri = params.get("uri")
                if not isinstance(uri, str) or not uri:
                    _proxy_send_response(msg_id, error={"code": -32602, "message": "Invalid params"})
                    continue
                if uri.startswith("file://"):
                    raw_path = uri.replace("file://", "", 1)
                    resolved = _proxy_resolve_workspace_path(workspace_root, raw_path)
                    if not resolved:
                        _proxy_send_response(msg_id, error={"code": -32602, "message": "Path outside workspace"})
                        continue
                    content = _proxy_read_text_file(resolved)
                    if content is None:
                        _proxy_send_response(msg_id, error={"code": -32602, "message": "File not found"})
                        continue
                    _proxy_send_response(msg_id, {"contents": [{"uri": uri, "text": content}]})
                    continue
                if uri == "workspace://files":
                    files = _proxy_list_py_files(workspace_root, 5000)
                    _proxy_send_response(msg_id, {"contents": [{"uri": uri, "text": json.dumps(files)}]})
                    continue
                if uri == "workspace://structure":
                    tree = _proxy_workspace_tree(workspace_root, 6)
                    _proxy_send_response(msg_id, {"contents": [{"uri": uri, "text": json.dumps(tree)}]})
                    continue
                _proxy_send_response(msg_id, error={"code": -32601, "message": "Resource not found"})
                continue

            _proxy_send_response(msg_id, error={"code": -32601, "message": "Method not found"})
        except Exception as e:
            _proxy_send_response(msg_id, error={"code": -32000, "message": "Unhandled error", "data": str(e)})


# ==================== MAIN ====================

def main():
    """Main entrypoint for the server."""
    try:
        if _is_proxy_mode():
            _run_proxy_stdio()
            return

        start_initialization_background()
        
        # Run the FastMCP server
        port = int(os.environ.get("PORT", 8080))
        host = os.environ.get("HOST", "0.0.0.0")
        
        logger.info(f"Starting Pylance MCP Pro on {host}:{port}")
        mcp.run(transport="stdio")
        
    except KeyboardInterrupt:
        logger.info("Server stopped by user")
    except Exception as e:
        logger.error(f"Server error: {e}", exc_info=True)
        sys.exit(1)
    finally:
        # End conversation logging
        if conv_logger and conversation_id:
            conv_logger.end_conversation(conversation_id)
            logger.info(f"Ended conversation logging: conversation_id={conversation_id}")
        
        # Stop language server bridge
        if bridge:
            bridge.stop()


if __name__ == "__main__":
    # Handle --test flag for installation testing
    if len(sys.argv) > 1 and sys.argv[1] == '--test':
        print(" Testing Pylance MCP Server dependencies...")
        try:
            # Test FastMCP import
            from fastmcp import FastMCP
            print(" FastMCP: OK")
            
            # Test Pylance bridge import
            from mcp_server.pylance_bridge import PylanceBridge
            print(" PylanceBridge: OK")
            
            # Test if we can find Pyright
            import subprocess
            try:
                result = subprocess.run(['pyright', '--version'], 
                                       capture_output=True, 
                                       text=True,
                                       timeout=5)
                if result.returncode == 0:
                    version = result.stdout.strip()
                    print(f" Pyright: {version}")
                else:
                    print("  Pyright not found (will auto-install on first run)")
            except FileNotFoundError:
                print("  Pyright not found (will auto-install on first run)")
            except subprocess.TimeoutExpired:
                print("  Pyright check timeout")
            
            # Test workspace detection
            workspace_test = Path(os.environ.get("WORKSPACE_ROOT", os.getcwd()))
            print(f" Workspace: {workspace_test}")
            
            print()
            print(" All dependency tests passed!")
            sys.exit(0)
            
        except ImportError as e:
            print(f" Missing dependency: {e}")
            print("   Run: pip install -r requirements.txt")
            sys.exit(1)
        except Exception as e:
            print(f" Test failed: {e}")
            sys.exit(1)
    
    # Normal server startup
    main()
